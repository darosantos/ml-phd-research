# -*- coding: utf-8 -*-
"""Test RF with ObliqueTree of TorshaMajumder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/149PqcMPRx7kiNEbJeYx2bW20GoqFDFiV

# **Test RF with ObliqueTree of TorshaMajumder**

https://github.com/valevalerio/Ensemble_Of_Oblique_Decision_Trees
"""

FOLDER_ROOT = '/content/drive/MyDrive/Testes e Experimentos/Testes/lib.external'
import sys
sys.path.append(FOLDER_ROOT)

import pandas as pd

import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import OneHotEncoder

df_stream = pd.read_csv('https://github.com/scikit-multiflow/streaming-datasets/raw/master/agr_a.csv',
                        engine='c', low_memory=True, memory_map=True)

X = df_stream[df_stream.columns[:-1]]
y = df_stream['class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=100)

"""Testa as Ã¡rvores obliquas individualmente"""

from TorshaMajumder.Decision_trees.CO2 import ContinuouslyOptimizedObliqueTree, CO2Classifier
from TorshaMajumder.Decision_trees.segmentor import Twoing, MSE, MeanSegmentor
from TorshaMajumder.Decision_trees.split_criteria import gini, twoing

# Continuous Optimization of Oblique Splits (CO2) by [Norouzi et al.]
# CO2Classifier(MSE(),MeanSegmentor(), max_depth=50, min_samples_split=2, nu=4.0, tau=10, tol=1e-3, eta=0.01)
co2t = ContinuouslyOptimizedObliqueTree(impurity=MSE(),
                                        segmentor=MeanSegmentor(), 
                                        max_depth=5,
                                        min_samples_split=2,
                                        nu=1.0,
                                        tau=10,
                                        tol=1e-3,
                                        eta=0.1)

co2t.fit(X_train.to_numpy(copy=True), y_train.to_numpy(copy=True))

y_pred = co2t.predict(X_test.to_numpy(copy=True))

print('Acc: ', accuracy_score(y_test, y_pred))

from TorshaMajumder.Decision_trees.HouseHolder_CART import HouseHolderCART, HHCartClassifier
from TorshaMajumder.Decision_trees.segmentor import Twoing, MSE, MeanSegmentor
from TorshaMajumder.Decision_trees.split_criteria import gini, twoing

# HouseHolder CART-A by [Wickramarachchi et al.]
# HHCartClassifier(MSE(),MeanSegmentor(), max_depth=50, min_samples_split=2, alpha=None))
hhc = HouseHolderCART(impurity=MSE(),
                      segmentor=MeanSegmentor(),
                      max_depth=5,
                      min_samples_split=2,
                      method='eig',
                      tau=10,
                      alpha=None)
hhc.fit(X_train.to_numpy(copy=True), y_train.to_numpy(copy=True))

y_pred = hhc.predict(X_test.to_numpy(copy=True))

print('Acc: ', accuracy_score(y_test, y_pred))

from TorshaMajumder.Decision_trees.NDT import Oblique_Classifier_1
from TorshaMajumder.Decision_trees.NDT import NDTClassifier
from TorshaMajumder.Decision_trees.segmentor import Twoing, MSE, MeanSegmentor
from TorshaMajumder.Decision_trees.split_criteria import gini, twoing

# Non-Linear Decision Trees by [Ittner et al.]
# 
ndtc = NDTClassifier(criterion="gini",
                     max_depth=3,
                     min_samples_split=2,
                     min_features_split=1)
ndtc.fit(X_train.to_numpy(copy=True), y_train.to_numpy(copy=True))

y_pred = ndtc.predict(X_test.to_numpy(copy=True))

print('Acc: ', accuracy_score(y_test, y_pred))

import TorshaMajumder.Decision_trees.OC1_tree_structure
import TorshaMajumder.Decision_trees.Oblique_Classifier_1
from TorshaMajumder.Decision_trees.NDT import NDTClassifier
from TorshaMajumder.Decision_trees.segmentor import Twoing, MSE, MeanSegmentor
from TorshaMajumder.Decision_trees.split_criteria import gini, twoing

# Non-Linear Decision Trees by [Ittner et al.]
# 
ndtc = NDTClassifier(criterion="gini",
                     max_depth=3,
                     min_samples_split=2,
                     min_features_split=1)
ndtc.fit(X_train.to_numpy(copy=True), y_train.to_numpy(copy=True))

y_pred = ndtc.predict(X_test.to_numpy(copy=True))

print('Acc: ', accuracy_score(y_test, y_pred))